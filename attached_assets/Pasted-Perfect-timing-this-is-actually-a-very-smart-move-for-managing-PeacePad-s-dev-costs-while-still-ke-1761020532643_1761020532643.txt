Perfect timing ‚Äî this is actually a very smart move for managing PeacePad‚Äôs dev costs while still keeping your AI mediation feature working properly during tests. Here‚Äôs how we can structure it:

‚∏ª

üß† Goal

Create a mock AI response database that mimics real mediation tone analysis and response behavior for development, instead of making live API calls to ChatGPT.
Then, in production, switch back to a lighter legacy OpenAI model (like gpt-3.5-turbo or gpt-4o-mini) only when needed.

‚∏ª

‚öôÔ∏è Implementation Plan for Replit

1Ô∏è‚É£ Mock AI Response Database (for DEV only)

We‚Äôll create a small JSON file or local SQLite DB that holds sample responses based on:
	‚Ä¢	Tone (e.g., calm, frustrated, defensive, reflective)
	‚Ä¢	Category (e.g., parenting discussion, scheduling conflict, expense disagreement)
	‚Ä¢	Response Type (suggestion, empathy prompt, neutral summary)

Example (JSON snippet):

[
  {
    "tone": "frustrated",
    "category": "scheduling",
    "ai_response": "It sounds like both of you are feeling unheard about the schedule. How about we take a breath and review one week at a time?"
  },
  {
    "tone": "calm",
    "category": "expense",
    "ai_response": "You both seem aligned on the main expenses. Let‚Äôs make sure each transaction is visible to both of you before it‚Äôs finalized."
  },
  {
    "tone": "defensive",
    "category": "child_update",
    "ai_response": "It might help to focus on your shared goal ‚Äî keeping your child‚Äôs day smooth ‚Äî rather than who‚Äôs right or wrong."
  }
]

You can store this as /mock/ai_responses.json and load it dynamically depending on the detected context.

‚∏ª

2Ô∏è‚É£ Replit Environment Toggle

In your Replit .env or config file, define:

ENV=DEV
AI_MODE=MOCK

Then in your code:

if (process.env.AI_MODE === "MOCK") {
  const mockResponses = require('./mock/ai_responses.json');
  const matched = mockResponses.find(r => r.tone === userTone && r.category === category);
  return matched ? matched.ai_response : "Let's take a step back and revisit this calmly.";
} else {
  // Use production API
  const completion = await openai.chat.completions.create({
    model: "gpt-3.5-turbo",  // lightweight model for prod
    messages: [{ role: "user", content: userMessage }]
  });
  return completion.choices[0].message.content;
}


‚∏ª

3Ô∏è‚É£ Production Optimization

When deploying to production:
	‚Ä¢	Switch .env to:

ENV=PROD
AI_MODE=LIVE
OPENAI_MODEL=gpt-3.5-turbo


	‚Ä¢	Limit live AI usage only to critical mediation features (tone summary or resolution suggestions).
	‚Ä¢	Cache AI outputs (e.g., in Redis or a local store) to reduce repeated costs.

‚∏ª

4Ô∏è‚É£ Optional Enhancement: Tone Detection Mock

If your mock AI should also simulate tone detection, you can extend the dataset with ‚Äúuser tone inputs‚Äù and sample ‚Äútone outputs‚Äù for testing.

Example:

{
  "input": "You never listen to what I say about the weekends!",
  "detected_tone": "angry",
  "ai_response": "I can hear that this topic is stressful. Maybe let‚Äôs refocus on what‚Äôs most important to the kids this weekend."
}


‚∏ª

‚úÖ Benefits
	‚Ä¢	Zero token cost during dev
	‚Ä¢	Offline capability ‚Äî devs can test without network latency
	‚Ä¢	Consistent test results for Playwright E2E
	‚Ä¢	Easy switch to production AI

‚∏ª

Would you like me to create the full mock AI JSON dataset (expanded version with 30‚Äì40 sample responses) and a small .env + switch script you can drop into Replit directly?
That way, you can plug it into PeacePad dev right away.